#!/bin/bash

create_encrypted () {
	enc_backup="${backup}.dat"
	# encrypt it
	openssl enc -aes-256-cbc -pbkdf2 -e -pass pass:$encryption_password \
	< "${backup}" \
	> $enc_backup
	#delete the tar.gz file
	rm "${backup}"
	echo "Sending backup $archivecount to backblaze"
	#check if file is great than 5G
	if [ $(du -s -B1 $enc_backup | awk '{ print $1 }') -gt 5000000000 ];
	then
		large file
	else
		small_file
	fi
	#delete the dat file
	rm $enc_backup 
}

large_file () {
	echo "File is greater than 5G. Sending with backblaze large file api"
	# initiate the large upload
	filename=$(date +%s)"${enc_backup}"
	start_large_upload_response=$(curl -s -H "Authorization: $token" \
	--data "{\"fileInfo\":{\"backup_job\":${backup_job}},\"bucketId\": \"${bucketid}\",\"fileName\": \"${enc_backup}\",\"contentType\": \"application/octet-stream\"}" \
	"${apiurl}b2_start_large_file")
	check_for_bad_request "$start_large_upload_response"
	large_upload_file_id=$(echo $start_large_upload_response | jq -r '.fileId')
	
	# get the large upload url
	large_upload_url_response=$(curl -s \
    -H "Authorization: $token" \
    --data "{\"fileId\": \"${large_upload_file_id}\"}" \
    "${apiurl}b2_get_upload_part_url")
	check_for_bad_request "$large_upload_url_response"
	large_upload_token=$(echo $large_upload_url_response | jq -r '.authorizationToken')
	large_upload_url=$(echo $large_upload_url_response | jq -r '.uploadUrl')

	# Prepare the large file be split into chunks
	echo "splitting large file into parts"
	split -b $size_of_part $enc_backup bz_chunk_
	chunk_names=$(ls -1 bz_chunk_*)

	# Upload the file parts
	part_no=1;
	part_sha1_array=();
	for chunk in $chunk_names;
	do
		echo "uploading part ${part_no}"
		chunk_sha1=$(openssl dgst -sha1 $chunk | awk '{print $2;}')
		part_sha1_array+=($chunk_sha1);
		size_of_chunk=$(ls -l $chunk | awk '{ print $5 }')
		
		large_upload_response=$(curl -s \
			-H "Authorization: $large_upload_token" \
			-H "X-Bz-Part-Number: $part_no" \
			-H "X-Bz-Content-Sha1: $chunk_sha1" \
			-H "Content-Length: $size_of_chunk" \
			--data-binary "@$chunk" \
			$large_upload_url)
		check_for_bad_request "$large_upload_response"
		let part_no+=1;
	done
	
	#Tell backblaze that the file has finished uploading
	JSON='{ "partSha1Array":[';
	for sha1 in "${part_sha1_array[@]}"; do
		JSON+="\"$sha1\",";
	done
	JSON="${JSON%?}";
	JSON+="], \"fileId\":\"$large_upload_file_id\"}";

	finish_large_upload_response=$(curl \
		-H "Authorization: $token" \
		-d "$JSON" \
		"${apiurl}b2_finish_large_file")
	check_for_bad_request "$finish_large_upload_response"
	# delete all the chunks
	rm bz_chunk_*
	echo $finish_large_upload_response | jq .
}

small_file () {
	filename=$(date +%s)"${enc_backup}"
	# get the url to upload the data to
	uploadurl_response=$(curl -s -H "Authorization: $token" \
	--data "{\"bucketId\": \"${bucketid}\"}" "${apiurl}b2_get_upload_url")
	check_for_bad_request "$uploadurl_response"
	
	uploadurl=$(echo $uploadurl_response | jq -r '.uploadUrl')
	uploadtoken=$(echo $uploadurl_response | jq -r '.authorizationToken')
	sha1_of_file=$(openssl dgst -sha1 $enc_backup | awk '{print $2;}')
	
	# upload the file
	upload_response=$(curl -s -T "$enc_backup" -X POST\
	-H "Authorization: $uploadtoken" \
	-H "X-Bz-File-Name: $filename" \
	-H "Content-Type: application/octet-stream" \
	-H "X-Bz-Content-Sha1: $sha1_of_file" \
	-H "X-Bz-Info-backup_job: $backup_job" \
	--data-binary "@$enc_backup" \
	$uploadurl)
	check_for_bad_request "$upload_response"

	echo $upload_response | jq .
}

check_for_bad_request () {
    if [ $(echo "$1" | jq '.status') != null ];
    then
		printf "Backblaze returned error\n"
		printf "$1" | jq '.'
		printf "Backup failed at" $(date)
		exit 1
    fi
}

echo "Backup started at" $(date)
cd /boot/config/plugins/bucketbackup/

#check if jq is installed
if ! [ -x "$(command -v jq)" ]; 
then
	echo 'Error: jq is not installed.'
	echo "Backup failed at" $(date)
	exit 1
fi

# make sure that a settings file exists before trying to initiate a backup
if [ ! -f settings.config ];
then
	echo 'Error: settings file does not exist.'
	echo "Backup failed at" $(date)
	exit 1
fi

echo "Getting authentication token"
api_id=$(cat settings.config | jq -r '.api_id')
api_key=$(cat settings.config | jq -r '.api_key')
backup_locations=$(cat settings.config | jq '.backup_location')
bucket_type=$(cat settings.config | jq '.bucket_type')
encryption_password=$(cat settings.config | jq -r '.encryption_password')
authurl=$(printf "https://api.backblazeb2.com/b2api/v2/")

authresponse=$(curl -s  "${authurl}b2_authorize_account" -u "${api_id}:${api_key}")
check_for_bad_request "$authresponse"

#response from backblaze authentication that will be used for sending files
token=$(echo $authresponse | jq -r '.authorizationToken')
apiurl=$(echo $authresponse | jq -r '.apiUrl')
apiurl+="/b2api/v2/"
accountid=$(echo $authresponse | jq -r '.accountId')
size_of_part=$( echo $authresponse | jq -r '.recommendedPartSize')
minimum_part_size=$( echo $authresponse | jq -r '.absoluteMinimumPartSize')

echo "Checking if bucketbackup bucket exists"
bucketname="unraid-bucket-backup"
list_buckets_response=$(curl -s \
    -H "Authorization: $token" \
    -d "{\"accountId\": \"${accountid}\"}" \
    "${apiurl}b2_list_buckets")
check_for_bad_request "$list_buckets_response"
found_bucket=0
bucketid=0
for bucket in $(echo "$list_buckets_response" | jq -c '.buckets[]');
do
	if [ $(echo $bucket | jq -r '.bucketName') == "$bucketname" ];
	then
		found_bucket=1
		bucketid=$(echo $bucket | jq -r '.bucketId')
	fi
done 

if [ $found_bucket == 1 ];
then
	echo "Bucketbackup bucket exists already"
else
	echo "Creating a bucket to hold the backup"
	#create a new bucket to hold the backups
	buckettype="allPrivate"
	bucketcreate_response=$(curl -s -H  "Authorization: $token" \
		--data "{\"accountId\":\"${accountid}\",\"bucketName\":\"${bucketname}\",\"bucketType\":\"${buckettype}\"}" \
		"${apiurl}b2_create_bucket")
	check_for_bad_request "$bucketcreate_response"
	bucketid=$(echo $bucketcreate_response | jq -r '.bucketId')
fi

#change directory to the disk array so the storage space on the flash drive isn't completely taken up
cd /mnt/user/
backup_dir=bucketbackup_archive_dir
if test -d "$backup_dir"; then
    rm -r "$backup_dir"
fi
mkdir "$backup_dir"
cd "$backup_dir"

# used to keep track of the number of archives in a backup
declare -i archivecount=0
# used to determine the file size of a single archive
declare -i filesize=0
declare -i filecount=0
backup="backup${archivecount}.tar.gz"
backup_job=$(date +%s)

for row in $(echo ${backup_locations} | jq -r .[]);
do
	echo "Backing up $row"
	while IFS= read -d '' -r file; do
		# Appending files to an existing archive does not work in unraid's shfs filesystem
		# So each filename is added to a file that will be prepended to the end of the tar command
		echo "$file" >> "tarfiles${archivecount}"
		# Get the file size of this file and add it to the accumalated file size. Once it reaches a certain limit then create an archive
		let filesize+=$(wc -c < "${file}")
		let filecount+=1
		# try to split the archive into 2GB parts. Or if there are more than 2000 files already then create a new archive
		if [ $filesize -gt 2000000000 ] || [ $filecount -gt 20000 ];
		then
			echo "creating archive of backup $archivecount"
			tar czf $backup -T "tarfiles${archivecount}"
			# archive size has been reached. gzip it, encrypt it and send it by either backblazes regular or large file upload routine
			create_encrypted
			#since the previous batch of files have been uploaded, move on to the next
			let archivecount+=1
			backup="backup${archivecount}.tar.gz"
			# reset everything back to zero for the next archive
			filecount=0
			files=""
			filesize=0
		fi
	done < <(find ${row} -type f -follow -print0)
done

# check to see if the list of files still exists. If it does then there are still some more files that need to be uploaded
if test -f "tarfiles${archivecount}";
then
	echo "creating archive of backup $archivecount"
	tar czf $backup -T "tarfiles${archivecount}"
	create_encrypted
fi

#remove temporary backup dir
cd ../
rm -r "$backup_dir"

echo "Backup finished at" $(date)
